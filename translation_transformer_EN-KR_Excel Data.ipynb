{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2657,"status":"ok","timestamp":1744108313179,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"HanDVdIkSBcQ","outputId":"c22daae6-1125-4a3b-c632-2e70720dd4a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":93712,"status":"ok","timestamp":1744108406894,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"nlVlEnRSdvY2","outputId":"d2debf3f-a358-4387-cfc1-88a4e939b442"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.4.0\n","  Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n","  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.0.106)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (12.1.105)\n","Collecting triton==3.0.0 (from torch==2.4.0)\n","  Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n","Using cached torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n","Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","Installing collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.2.0\n","    Uninstalling triton-2.2.0:\n","      Successfully uninstalled triton-2.2.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.19.3\n","    Uninstalling nvidia-nccl-cu12-2.19.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n","    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n","      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.2.0\n","    Uninstalling torch-2.2.0:\n","      Successfully uninstalled torch-2.2.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.17.0 requires torch==2.2.0, but you have torch 2.4.0 which is incompatible.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cudnn-cu12-9.1.0.70 nvidia-nccl-cu12-2.20.5 torch-2.4.0 triton-3.0.0\n"]}],"source":["!pip install torch==2.4.0"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"5dO8s1CdRXCP","executionInfo":{"status":"ok","timestamp":1744109015414,"user_tz":-540,"elapsed":85,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["import re\n","import os\n","import unicodedata\n","import urllib3\n","import zipfile\n","import shutil\n","import numpy as np\n","import pandas as pd\n","import torch\n","from collections import Counter\n","from tqdm import tqdm\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"daNvBfyoNrUd","executionInfo":{"status":"ok","timestamp":1744109016924,"user_tz":-540,"elapsed":36,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["num_samples = 33000"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"1VqQI8wYZr4b","executionInfo":{"status":"ok","timestamp":1744109017949,"user_tz":-540,"elapsed":80,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def preprocess_sentence(sent):\n","\n","    # 단어와 구두점 사이에 공백을 만듭니다.\n","    # Ex) \"he is a boy.\" => \"he is a boy .\"\n","    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n","\n","    # (가-힣, a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n","    sent = re.sub(r\"[^가-힣a-zA-Z?.!]+\", r\" \", sent)\n","\n","    # 다수 개의 공백을 하나의 공백으로 치환\n","    sent = re.sub(r\"\\s+\", \" \", sent)\n","    return sent"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"1h47J4q-pz2u","executionInfo":{"status":"ok","timestamp":1744109019679,"user_tz":-540,"elapsed":23,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def load_preprocessed_data_from_excel():\n","    encoder_input, decoder_input, decoder_target = [], [], []\n","\n","    # 엑셀 파일 읽기 (기본: 첫 번째 시트)\n","    df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/kor.xlsx\")\n","\n","    # 열 이름이 없다면 수동으로 지정해줘야 함\n","    # 예: df.columns = [\"src\", \"tar\"]\n","\n","    for i in range(min(num_samples, len(df))):\n","        tar_line = df.iloc[i, 0]  # 첫 번째 열: 한국어\n","        src_line = df.iloc[i, 1]  # 두 번째 열: 영어\n","\n","        # 전처리\n","        src_line = [w for w in preprocess_sentence(str(src_line)).split()]\n","        tar_line = preprocess_sentence(str(tar_line))\n","        tar_line_in = [w for w in (\"<sos> \" + tar_line).split()]\n","        tar_line_out = [w for w in (tar_line + \" <eos>\").split()]\n","\n","        encoder_input.append(src_line)\n","        decoder_input.append(tar_line_in)\n","        decoder_target.append(tar_line_out)\n","\n","    return encoder_input, decoder_input, decoder_target\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1744109022965,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"HmRKunDIVilV","outputId":"0279895a-58b7-4b80-d363-885c1b5ae7c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["전처리 전 영어 문장 : Have you had dinner?\n","전처리 후 영어 문장 : Have you had dinner ?\n","전처리 전 한국어 문장 : 저녁 먹었니?\n","전처리 후 한국어 문장 : 저녁 먹었니 ?\n"]}],"source":["# 전처리 테스트\n","en_sent = u\"Have you had dinner?\"\n","kr_sent = u\"저녁 먹었니?\"\n","\n","print('전처리 전 영어 문장 :', en_sent)\n","print('전처리 후 영어 문장 :',preprocess_sentence(en_sent))\n","print('전처리 전 한국어 문장 :', kr_sent)\n","print('전처리 후 한국어 문장 :', preprocess_sentence(kr_sent))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17503,"status":"ok","timestamp":1744109044090,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"aV6TYggPWKNK","outputId":"1466ccfa-ecd0-434b-f1d8-000aeaef8428"},"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력 : [['Do', 'you', 'work', 'at', 'a', 'City', 'bank', '?'], ['PURITO', 's', 'bestseller', 'which', 'recorded', 'th', 'rough', 'cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad', '.'], ['In', 'Chapter', 'Jesus', 'called', 'Lazarus', 'from', 'the', 'tomb', 'and', 'raised', 'him', 'from', 'the', 'dead', '.'], ['I', 'would', 'feel', 'grateful', 'to', 'know', 'how', 'many', 'stocks', 'will', 'be', 'secured', 'of', 'size', '.', 'and', '.'], ['fw', 'Kenzo', 'Tiger', 'Kids', 'and', 'refund', 'for', 'lacking', 'quantity', 'of', 'Kids', 'which', 'was', 'ordered', 'this', 'time', '.']]\n","디코더의 입력 : [['<sos>', '씨티은행에서', '일하세요', '?'], ['<sos>', '푸리토의', '베스트셀러는', '해외에서', '입소문만으로', '차', '완판을', '기록하였다', '.'], ['<sos>', '장에서는', '예수님이', '이번엔', '나사로를', '무덤에서', '불러내어', '죽은', '자', '가운데서', '살리셨습니다', '.'], ['<sos>', '.', '사이즈가', '몇', '개나', '더', '재입고', '될지', '제게', '알려주시면', '감사하겠습니다', '.'], ['<sos>', 'F', 'W', '겐조타이거', '키즈와', '그리고', '이번에', '주문한', '키즈', '중', '부족한', '수량에', '대한', '환불입니다', '.']]\n","디코더의 레이블 : [['씨티은행에서', '일하세요', '?', '<eos>'], ['푸리토의', '베스트셀러는', '해외에서', '입소문만으로', '차', '완판을', '기록하였다', '.', '<eos>'], ['장에서는', '예수님이', '이번엔', '나사로를', '무덤에서', '불러내어', '죽은', '자', '가운데서', '살리셨습니다', '.', '<eos>'], ['.', '사이즈가', '몇', '개나', '더', '재입고', '될지', '제게', '알려주시면', '감사하겠습니다', '.', '<eos>'], ['F', 'W', '겐조타이거', '키즈와', '그리고', '이번에', '주문한', '키즈', '중', '부족한', '수량에', '대한', '환불입니다', '.', '<eos>']]\n"]}],"source":["sents_en_in, sents_kr_in, sents_kr_out = load_preprocessed_data_from_excel()\n","print('인코더의 입력 :',sents_en_in[:5])\n","print('디코더의 입력 :',sents_kr_in[:5])\n","print('디코더의 레이블 :',sents_kr_out[:5])"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"UA7HnPq9WNuN","executionInfo":{"status":"ok","timestamp":1744109044144,"user_tz":-540,"elapsed":36,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def build_vocab(sents):\n","    word_list = []\n","\n","    for sent in sents:\n","        for word in sent:\n","            word_list.append(word)\n","\n","    # 각 단어별 등장 빈도를 계산하여 등장 빈도가 높은 순서로 정렬\n","    word_counts = Counter(word_list)\n","    vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n","\n","    word_to_index = {}\n","    word_to_index['<PAD>'] = 0\n","    word_to_index['<UNK>'] = 1\n","\n","    # 등장 빈도가 높은 단어일수록 낮은 정수를 부여\n","    for index, word in enumerate(vocab) :\n","        word_to_index[word] = index + 2\n","\n","    return word_to_index"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1744109069836,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"vGohYus2WUrc","outputId":"90856973-4be6-47c3-aa38-572cb7a36f4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["영어 단어 집합의 크기 : 20505, 한국어 단어 집합의 크기 : 64787\n"]}],"source":["src_vocab = build_vocab(sents_en_in)\n","tar_vocab = build_vocab(sents_kr_in + sents_kr_out)\n","\n","src_vocab_size = len(src_vocab)\n","tar_vocab_size = len(tar_vocab)\n","print(\"영어 단어 집합의 크기 : {:d}, 한국어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"8OC3uGHcaMUr","executionInfo":{"status":"ok","timestamp":1744109071793,"user_tz":-540,"elapsed":21,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["index_to_src = {v: k for k, v in src_vocab.items()}\n","index_to_tar = {v: k for k, v in tar_vocab.items()}\n","\n","def texts_to_sequences(sents, word_to_index):\n","    encoded_X_data = []\n","    for sent in tqdm(sents):\n","        index_sequences = []\n","        for word in sent:\n","            try:\n","                index_sequences.append(word_to_index[word])\n","            except KeyError:\n","                index_sequences.append(word_to_index['<UNK>'])\n","        encoded_X_data.append(index_sequences)\n","    return encoded_X_data"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":793,"status":"ok","timestamp":1744109075256,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"qXfCaAQ3aSWI","outputId":"2c74a81c-8774-4930-a2ba-1c209e24cf03"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 33000/33000 [00:00<00:00, 239815.70it/s]\n","100%|██████████| 33000/33000 [00:00<00:00, 59975.57it/s]\n","100%|██████████| 33000/33000 [00:00<00:00, 301378.58it/s]\n"]}],"source":["encoder_input = texts_to_sequences(sents_en_in, src_vocab)\n","decoder_input = texts_to_sequences(sents_kr_in, tar_vocab)\n","decoder_target = texts_to_sequences(sents_kr_out, tar_vocab)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1744109076256,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"D7yBRDOhwmS7","outputId":"85c08c54-a614-41fe-b9f2-6097709c924e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index: 0, 정수 인코딩 전: ['Do', 'you', 'work', 'at', 'a', 'City', 'bank', '?'], 정수 인코딩 후: [209, 11, 95, 32, 5, 1873, 800, 16]\n","Index: 1, 정수 인코딩 전: ['PURITO', 's', 'bestseller', 'which', 'recorded', 'th', 'rough', 'cuts', 'by', 'words', 'of', 'mouth', 'from', 'abroad', '.'], 정수 인코딩 후: [6173, 17, 10635, 83, 3437, 74, 1944, 5245, 38, 585, 8, 1393, 34, 1512, 2]\n","Index: 2, 정수 인코딩 전: ['In', 'Chapter', 'Jesus', 'called', 'Lazarus', 'from', 'the', 'tomb', 'and', 'raised', 'him', 'from', 'the', 'dead', '.'], 정수 인코딩 후: [114, 5246, 2772, 252, 10636, 34, 3, 5247, 9, 1806, 113, 34, 3, 2201, 2]\n","Index: 3, 정수 인코딩 전: ['I', 'would', 'feel', 'grateful', 'to', 'know', 'how', 'many', 'stocks', 'will', 'be', 'secured', 'of', 'size', '.', 'and', '.'], 정수 인코딩 후: [7, 75, 200, 2325, 4, 73, 175, 109, 2462, 26, 24, 6174, 8, 383, 2, 9, 2]\n","Index: 4, 정수 인코딩 전: ['fw', 'Kenzo', 'Tiger', 'Kids', 'and', 'refund', 'for', 'lacking', 'quantity', 'of', 'Kids', 'which', 'was', 'ordered', 'this', 'time', '.'], 정수 인코딩 후: [3764, 6175, 10637, 5248, 9, 714, 14, 4117, 594, 8, 5248, 83, 20, 763, 56, 48, 2]\n"]}],"source":["# 상위 5개의 샘플에 대해서 정수 인코딩 전, 후 문장 출력\n","# 인코더 입력이므로 <sos>나 <eos>가 없음\n","for i, (item1, item2) in zip(range(5), zip(sents_en_in, encoder_input)):\n","    print(f\"Index: {i}, 정수 인코딩 전: {item1}, 정수 인코딩 후: {item2}\")"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"ai6tPS4Wwp5x","executionInfo":{"status":"ok","timestamp":1744109077544,"user_tz":-540,"elapsed":35,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def pad_sequences(sentences, max_len=None):\n","    # 최대 길이 값이 주어지지 않을 경우 데이터 내 최대 길이로 패딩\n","    if max_len is None:\n","        max_len = max([len(sentence) for sentence in sentences])\n","\n","    features = np.zeros((len(sentences), max_len), dtype=int)\n","    for index, sentence in enumerate(sentences):\n","        if len(sentence) != 0:\n","            features[index, :len(sentence)] = np.array(sentence)[:max_len]\n","    return features"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"bImM_qStws6c","executionInfo":{"status":"ok","timestamp":1744109079242,"user_tz":-540,"elapsed":85,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["encoder_input = pad_sequences(encoder_input)\n","decoder_input = pad_sequences(decoder_input)\n","decoder_target = pad_sequences(decoder_target)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1744109081237,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"2_aU0nyrwtyg","outputId":"38024f4f-d0f1-4969-8a4b-3395b555e52b"},"outputs":[{"output_type":"stream","name":"stdout","text":["인코더의 입력의 크기(shape) : (33000, 43)\n","디코더의 입력의 크기(shape) : (33000, 25)\n","디코더의 레이블의 크기(shape) : (33000, 25)\n"]}],"source":["print('인코더의 입력의 크기(shape) :',encoder_input.shape)\n","print('디코더의 입력의 크기(shape) :',decoder_input.shape)\n","print('디코더의 레이블의 크기(shape) :',decoder_target.shape)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1744109082195,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"Oc77F3jiwu9Z","outputId":"7d5a5f48-6343-42ff-9d2e-3be441bda3fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["랜덤 시퀀스 : [ 3496 12292 20228 ... 12734   309 18328]\n"]}],"source":["indices = np.arange(encoder_input.shape[0])\n","np.random.shuffle(indices)\n","print('랜덤 시퀀스 :',indices)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"SurYKGrew0ZR","executionInfo":{"status":"ok","timestamp":1744109082996,"user_tz":-540,"elapsed":74,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1744109083770,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"_CqGerZDw2Z1","outputId":"7d25d229-6dd2-41d0-c0b7-a7373e99a023"},"outputs":[{"output_type":"stream","name":"stdout","text":["['I', 'had', 'to', 'sleep', 'in', 'a', 'place', 'called', 'the', 'season', 'room', 'there', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","['<sos>', '그곳에서', '나는', '시즌', '방이라는', '곳에서', '자게', '되었어', '.', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n","['그곳에서', '나는', '시즌', '방이라는', '곳에서', '자게', '되었어', '.', '<eos>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n"]}],"source":["print([index_to_src[word] for word in encoder_input[30997]])\n","print([index_to_tar[word] for word in decoder_input[30997]])\n","print([index_to_tar[word] for word in decoder_target[30997]])"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1744109086128,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"VvTk0Zjxw2iF","outputId":"4cc11237-bc33-4906-a326-b79c5daf5ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["검증 데이터의 개수 : 3300\n"]}],"source":["n_of_val = int(33000*0.1)\n","print('검증 데이터의 개수 :',n_of_val)"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"vF2awDslw8Sl","executionInfo":{"status":"ok","timestamp":1744109087859,"user_tz":-540,"elapsed":31,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1744109089520,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"9nEDHtBpw-il","outputId":"a7b03961-9add-47a8-da91-dd6fd7bc815d"},"outputs":[{"output_type":"stream","name":"stdout","text":["훈련 source 데이터의 크기 : (29700, 43)\n","훈련 target 데이터의 크기 : (29700, 25)\n","훈련 target 레이블의 크기 : (29700, 25)\n","테스트 source 데이터의 크기 : (3300, 43)\n","테스트 target 데이터의 크기 : (3300, 25)\n","테스트 target 레이블의 크기 : (3300, 25)\n"]}],"source":["print('훈련 source 데이터의 크기 :',encoder_input_train.shape)\n","print('훈련 target 데이터의 크기 :',decoder_input_train.shape)\n","print('훈련 target 레이블의 크기 :',decoder_target_train.shape)\n","print('테스트 source 데이터의 크기 :',encoder_input_test.shape)\n","print('테스트 target 데이터의 크기 :',decoder_input_test.shape)\n","print('테스트 target 레이블의 크기 :',decoder_target_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXfgdLH_aHiW"},"outputs":[],"source":["# Google Colab에서 노트북을 실행하실 때에는\n","# https://tutorials.pytorch.kr/beginner/colab 를 참고하세요.\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"jnSU2_VDaHiX"},"source":["`nn.Transformer` 와 torchtext로 언어 번역하기\n","=============================================\n","\n","이 튜토리얼에서는,\n","\n",":   -   Transformer(트랜스포머)를 사용한 번역 모델을 바닥부터 학습하는\n","        방법을 배워보겠습니다.\n","    -   [Multi30k](http://www.statmt.org/wmt16/multimodal-task.html#task1)\n","        데이터셋을 사용하여 독일어(German)를 영어(English)로 번역하는\n","        모델을 학습해보겠습니다.\n"]},{"cell_type":"markdown","metadata":{"id":"5yrctszqaHiZ"},"source":["데이터 구하고 처리하기\n","======================\n","\n","[torchtext 라이브러리](https://pytorch.org/text/stable/)에는 언어 번역\n","모델을 생성하기 위한 데이터셋을 쉽게 만들 수 있는 도구들이 있습니다. 이\n","튜토리얼에서는 torchtext의 내장(inbuilt) 데이터셋을 어떻게 사용하고,\n","원시(raw) 텍스트 문장을 토큰화(tokenize)하고, 토큰을 텐서로 수치화하는\n","방법을 살펴보겠습니다. 출발어(source)-도착어(target) 원시(raw) 문장을\n","생성하기 위해서는 [torchtext 라이브러리의 Multi30k\n","데이터셋](https://pytorch.org/text/stable/datasets.html#multi30k) 을\n","사용하겠습니다.\n","\n","torchtext 데이터셋에 접근하기 전에, <https://github.com/pytorch/data> 을\n","참고하여 torchdata를 설치하시기 바랍니다.\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":97570,"status":"ok","timestamp":1744108504514,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"winZr7BGaIxY","outputId":"0f85778b-44e4-4e84-c67f-0624706a1899"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchdata==0.8.0\n","  Using cached torchdata-0.8.0-cp311-cp311-manylinux1_x86_64.whl.metadata (5.4 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.8.0) (2.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.8.0) (2.32.3)\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.8.0) (2.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (4.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.8.0) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata==0.8.0) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.8.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.8.0) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.8.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata==0.8.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2->torchdata==0.8.0) (1.3.0)\n","Using cached torchdata-0.8.0-cp311-cp311-manylinux1_x86_64.whl (2.7 MB)\n","Installing collected packages: torchdata\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.7.1\n","    Uninstalling torchdata-0.7.1:\n","      Successfully uninstalled torchdata-0.7.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.17.0 requires torch==2.2.0, but you have torch 2.4.0 which is incompatible.\n","torchtext 0.17.0 requires torchdata==0.7.1, but you have torchdata 0.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torchdata-0.8.0\n","Requirement already satisfied: torchtext==0.17.0 in /usr/local/lib/python3.11/dist-packages (0.17.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.32.3)\n","Collecting torch==2.2.0 (from torchtext==0.17.0)\n","  Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.0) (2.0.2)\n","Collecting torchdata==0.7.1 (from torchtext==0.17.0)\n","  Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (4.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->torchtext==0.17.0)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.0.106)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->torchtext==0.17.0)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.0->torchtext==0.17.0) (12.1.105)\n","Collecting triton==2.2.0 (from torch==2.2.0->torchtext==0.17.0)\n","  Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1->torchtext==0.17.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext==0.17.0) (12.5.82)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.0) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.0->torchtext==0.17.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.0->torchtext==0.17.0) (1.3.0)\n","Using cached torch-2.2.0-cp311-cp311-manylinux1_x86_64.whl (755.5 MB)\n","Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Using cached triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","Installing collected packages: triton, nvidia-nccl-cu12, nvidia-cudnn-cu12, torch, torchdata\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.0.0\n","    Uninstalling triton-3.0.0:\n","      Successfully uninstalled triton-3.0.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.20.5\n","    Uninstalling nvidia-nccl-cu12-2.20.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n","    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.0\n","    Uninstalling torch-2.4.0:\n","      Successfully uninstalled torch-2.4.0\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.8.0\n","    Uninstalling torchdata-0.8.0:\n","      Successfully uninstalled torchdata-0.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-nccl-cu12-2.19.3 torch-2.2.0 torchdata-0.7.1 triton-2.2.0\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (3.1.1)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n"]}],"source":["#!pip install torch==2.4.0\n","!pip install torchdata==0.8.0\n","!pip install torchtext==0.17.0\n","!pip install portalocker\n","!pip install openpyxl"]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"executionInfo":{"elapsed":19954,"status":"ok","timestamp":1744108656275,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"vF4dKqgmaHia"},"outputs":[],"source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from typing import Iterable, List\n","import pandas as pd\n","\n","# 엑셀에서 열 이름 없이 불러오기\n","df = pd.read_excel(\"/content/drive/MyDrive/Colab Notebooks/kor.xlsx\", header=None)  # 열 이름 없음\n","df = df.iloc[:100000]  # 앞에서 5000개만 사용\n","train_data = list(zip(df[1], df[0]))  # 영어, 한국어 순으로 zip\n","\n","# 1. 언어 설정 (영어-한국어)\n","SRC_LANGUAGE = 'en'\n","TGT_LANGUAGE = 'ko'\n","\n","token_transform = {}\n","vocab_transform = {}"]},{"cell_type":"markdown","metadata":{"id":"T39pv90laHib"},"source":["출발어(source)와 목적어(target)의 토크나이저(tokenizer)를 생성합니다.\n","아래 필요 사항(dependency)을 모두 설치해주세요.\n","\n","``` {.sourceCode .python}\n","pip install -U torchdata\n","pip install -U spacy\n","python -m spacy download ko_core_web_sm\n","python -m spacy download en_core_news_sm\n","```\n","위와 같은 내용으로 수정하려 했으나 'en_core_news_sm', 'ko_core_web_sm'은 공식적으로 존재하지 않음"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1556,"status":"ok","timestamp":1744108715854,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"BPufGdW0aHib","outputId":"240e330e-9b0e-4d1b-a910-7cd68fbdfc34"},"outputs":[{"output_type":"stream","name":"stdout","text":["English vocab size: 51455\n","Korean vocab size: 127510\n","Sample tokens (EN): ['Bible', \"Coloring'\", 'is', 'a', 'coloring', 'application', 'that', 'allows', 'you', 'to', 'experience', 'beautiful', 'stories', 'in', 'the', 'Bible.']\n","Sample tokens (KO): [\"'Bible\", \"Coloring'은\", '성경의', '아름다운', '이야기를', '체험', '할', '수', '있는', '컬러링', '앱입니다.']\n","Sample indices (EN): [7431, 27332, 10, 7, 9292, 1133, 13, 3492, 8, 6, 370, 376, 2213, 12, 5, 11515]\n","Sample indices (KO): [43809, 49017, 35660, 447, 370, 7461, 20, 5, 13, 117720, 12878]\n"]}],"source":["# 간단한 띄어쓰기 기반 토크나이저 사용\n","token_transform[SRC_LANGUAGE] = lambda x: x.strip().split()\n","token_transform[TGT_LANGUAGE] = lambda x: x.strip().split()\n","\n","\n","# 토큰 목록을 생성하기 위한 헬퍼(helper) 함수\n","def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    for data_sample in data_iter:\n","        yield token_transform[language](data_sample[language_index[language]])\n","\n","# 특수 기호(symbol)와 인덱스를 정의합니다\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","# 토큰들이 어휘집(vocab)에 인덱스 순서대로 잘 삽입되어 있는지 확인합니다\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n","\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[ln] = build_vocab_from_iterator(\n","        yield_tokens(train_data, ln),\n","        min_freq=1,\n","        specials=special_symbols,\n","        special_first=True\n","    )\n","    vocab_transform[ln].set_default_index(UNK_IDX)\n","\n","# 확인용 출력\n","print(f\"English vocab size: {len(vocab_transform[SRC_LANGUAGE])}\")\n","print(f\"Korean vocab size: {len(vocab_transform[TGT_LANGUAGE])}\")\n","print(f\"Sample tokens (EN): {token_transform['en'](train_data[0][0])}\")\n","print(f\"Sample tokens (KO): {token_transform['ko'](train_data[0][1])}\")\n","print(f\"Sample indices (EN): {vocab_transform['en'](token_transform['en'](train_data[0][0]))}\")\n","print(f\"Sample indices (KO): {vocab_transform['ko'](token_transform['ko'](train_data[0][1]))}\")"]},{"cell_type":"markdown","metadata":{"id":"5MxlXznKaHic"},"source":["Transformer를 사용한 시퀀스-투-시퀀스(Seq2Seq) 신경망\n","=====================================================\n","\n","Transformer(트랜스포머)는 기계번역 작업(task)을 위해 [\\\"Attention is all\n","you\n","need\\\"](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n","논문에 소개된 Seq2Seq 모델입니다. 아래에서 Transformer를 사용한 Seq2Seq\n","신경망을 만들어보겠습니다. 신경망은 세 부분으로 구성되는데, 첫번째\n","부분은 임베딩 계층(embedding layer)입니다. 이 계층은 입력 인덱스의\n","텐서를 입력 임베딩의 해당하는 텐서로 변환합니다. 이러한 임베딩은 입력\n","토큰의 위치 정보(position information)를 모델에 전달하기 위해 위치\n","인코딩(positional encoding)을 추가합니다. 두번째 부분은 실제\n","[Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)\n","모델입니다. 마지막으로 Transformer 모델의 출력을 선형 계층에 통과시켜\n","도착어의 각 토큰에 대한 정규화되지 않은 확률(un-normalized\n","probability)로 제공합니다.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zjNLghfBaHic","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744108506518,"user_tz":-540,"elapsed":1974,"user":{"displayName":"믕승","userId":"15077172607721463263"}},"outputId":"d50e9f39-ab72-4d12-fe1d-69e9b366d964"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","A module that was compiled using NumPy 1.x cannot be run in\n","NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n","versions of NumPy, modules must be compiled with NumPy 2.0.\n","Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n","\n","If you are a user of the module, the easiest solution will be to\n","downgrade to 'numpy<2' or try to upgrade the affected module.\n","We expect that some modules will need time to support NumPy 2.\n","\n","Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n","  File \"<frozen runpy>\", line 88, in _run_code\n","  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n","    ColabKernelApp.launch_instance()\n","  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n","    await self.process_one()\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n","    await dispatch(*args)\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n","    await result\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n","    reply_content = await reply_content\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n","    res = shell.run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n","    return super().run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-4-5ae5bafcf60b>\", line 1, in <cell line: 0>\n","    from torch import Tensor\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1471, in <module>\n","    from .functional import *  # noqa: F403\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n","    import torch.nn.functional as F\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n","    from .modules import *  # noqa: F403\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n","    from .transformer import TransformerEncoder, TransformerDecoder, \\\n","  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n","    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n","/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n","  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"]}],"source":["from torch import Tensor\n","import torch\n","import torch.nn as nn\n","from torch.nn import Transformer\n","import math\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 단어 순서 개념(notion)을 토큰 임베딩에 도입하기 위한 위치 인코딩(positional encoding)을 위한 헬퍼 모듈(Module)\n","class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","# 입력 인덱스의 텐서를 해당하는 토큰 임베딩의 텐서로 변환하기 위한 헬퍼 모듈(Module)\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","# Seq2Seq 신경망\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)"]},{"cell_type":"markdown","metadata":{"id":"-eLsqD4FaHid"},"source":["학습하는 동안, 모델이 예측할 때 정답(이후 출현하는 단어)을 보지 못하도록\n","하는 후속 단어 마스크(subsequent word mask)가 필요합니다. 또한, 출발어와\n","도착어의 패딩(padding) 토큰들 또한 숨겨야 합니다. 아래에 두 가지 모두를\n","처리할 함수를 정의해보겠습니다.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LABZXEQUaHie","executionInfo":{"status":"ok","timestamp":1744108506575,"user_tz":-540,"elapsed":53,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"markdown","metadata":{"id":"Z2xJW-nDaHie"},"source":["이제 모델의 매개변수를 정의하고 객체를 생성(instantiate)해보겠습니다.\n","아래처럼 학습 단계에서 사용할 손실 함수(loss function)를 교차 엔트로피\n","손실(cross-entropy loss)로 정의하고, 옵티마이저(optimizer)도 정의합니다.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7759,"status":"ok","timestamp":1744108732345,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"zeEg3dwOaHie","outputId":"58863405-5ecc-43c1-9a2b-a9d9b2912388"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 128 #128에서 수정\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(DEVICE)\n","\n","loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"markdown","metadata":{"id":"_tq5yYJIaHif"},"source":["대조(Collation)\n","===============\n","\n","위의 `데이터 구하고 처리하기` 장에서 봤듯이, 데이터 반복자(iterator)는\n","원시 문자열의 쌍을 생성합니다. 이 문자열 쌍들을 이전에 정의한 `Seq2Seq`\n","신경망에서 처리할 수 있도록 텐서 묶음(batched tensor)으로 변환해야\n","합니다. 이제 원시 문자열들의 묶음(batch)을 텐서 묶음으로 변환하여 모델에\n","직접 전달할 수 있도록 하는 대응어(collate) 함수를 정의해보겠습니다.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"rMJOC0nlaHif","executionInfo":{"status":"ok","timestamp":1744108747166,"user_tz":-540,"elapsed":37,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","\n","# 순차적인 작업들을 하나로 묶는 헬퍼 함수\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","# BOS/EOS를 추가하고 입력 순서(sequence) 인덱스에 대한 텐서를 생성하는 함수\n","def tensor_transform(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","# 출발어(src)와 도착어(tgt) 원시 문자열들을 텐서 인덱스로 변환하는 변형(transform)\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln], # 토큰화(Tokenization)\n","                                               vocab_transform[ln], # 수치화(Numericalization)\n","                                               tensor_transform) # BOS/EOS를 추가하고 텐서를 생성\n","\n","\n","# 데이터를 텐서로 조합(collate)하는 함수\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"]},{"cell_type":"markdown","metadata":{"id":"Rd3qghRkaHif"},"source":["각 에폭(epoch)마다 호출할 학습 및 검증(evaluation) 단계를\n","정의해보겠습니다.\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"QPk1DXE-aHif","executionInfo":{"status":"ok","timestamp":1744108751815,"user_tz":-540,"elapsed":1536,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","\n","class CustomTranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        src, tgt = self.data[idx]\n","        return src, tgt\n","\n","train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n","\n","def train_epoch(model, optimizer):\n","    model.train()\n","    losses = 0\n","    train_dataset = CustomTranslationDataset(train_data)\n","    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n","\n","    for src, tgt in train_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        optimizer.zero_grad()\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(list(train_dataloader))\n","\n","\n","def evaluate(model):\n","    model.eval()\n","    losses = 0\n","\n","    val_dataset = CustomTranslationDataset(val_data)\n","    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in val_dataloader:\n","        src = src.to(DEVICE)\n","        tgt = tgt.to(DEVICE)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","\n","    return losses / len(list(val_dataloader))"]},{"cell_type":"markdown","metadata":{"id":"OZ8m4p1RaHif"},"source":["이제 모델 학습을 위한 모든 요소가 준비되었습니다. 학습을 해보겠습니다!\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5745962,"status":"ok","timestamp":1744094681262,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"S-xmAoASaHig","outputId":"2167e607-5667-4b9d-85a8-911fd4d089fb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Train loss: 8.448, Val loss: 7.827, Epoch time = 298.824s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 2, Train loss: 7.408, Val loss: 7.355, Epoch time = 303.669s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 3, Train loss: 6.831, Val loss: 7.026, Epoch time = 304.520s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 4, Train loss: 6.377, Val loss: 6.819, Epoch time = 303.620s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 5, Train loss: 6.005, Val loss: 6.646, Epoch time = 303.690s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 6, Train loss: 5.690, Val loss: 6.558, Epoch time = 303.086s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 7, Train loss: 5.412, Val loss: 6.448, Epoch time = 303.776s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 8, Train loss: 5.163, Val loss: 6.374, Epoch time = 303.942s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 9, Train loss: 4.932, Val loss: 6.336, Epoch time = 303.860s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 10, Train loss: 4.720, Val loss: 6.347, Epoch time = 304.016s\n","Epoch: 11, Train loss: 4.521, Val loss: 6.405, Epoch time = 304.147s\n","Epoch: 12, Train loss: 4.332, Val loss: 6.315, Epoch time = 302.532s\n","✔️ 모델 저장 완료 (성능 향상됨)\n","Epoch: 13, Train loss: 4.157, Val loss: 6.331, Epoch time = 304.814s\n","Epoch: 14, Train loss: 3.990, Val loss: 6.426, Epoch time = 304.419s\n","Epoch: 15, Train loss: 3.832, Val loss: 6.379, Epoch time = 304.944s\n","Epoch: 16, Train loss: 3.680, Val loss: 6.340, Epoch time = 303.701s\n","Epoch: 17, Train loss: 3.538, Val loss: 6.367, Epoch time = 302.998s\n","Epoch: 18, Train loss: 3.402, Val loss: 6.369, Epoch time = 301.909s\n"]}],"source":["from timeit import default_timer as timer\n","NUM_EPOCHS = 18\n","\n","# Initialize best_valid_loss with a very large value\n","best_valid_loss = float('inf')\n","\n","for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = timer()\n","    train_loss = train_epoch(transformer, optimizer)\n","    end_time = timer()\n","    val_loss = evaluate(transformer)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","    # ✅ 검증 손실이 더 좋아졌을 때 모델 저장\n","    if val_loss < best_valid_loss:\n","        best_valid_loss = val_loss\n","        torch.save(transformer.state_dict(), '/content/drive/MyDrive/Colab Notebooks/best_transformer_model_EN-KR.pth')\n","        print(\"✔️ 모델 저장 완료 (성능 향상됨)\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUozqMfB4bTC"},"outputs":[],"source":["import numpy\n","from torch.utils.data import DataLoader\n","\n","# 탐욕(greedy) 알고리즘을 사용하여 출력 순서(sequence)를 생성하는 함수\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(DEVICE)\n","    src_mask = src_mask.to(DEVICE)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len-1):\n","        memory = memory.to(DEVICE)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","# 입력 문장을 도착어로 번역하는 함수\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    #return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\") # numpy()문제발생으로 인해\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(tgt_tokens.cpu().tolist())).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\") # numpy() 제거 .tolist()로 수정"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":147},"executionInfo":{"elapsed":52,"status":"error","timestamp":1744107122209,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"GBfuIfQVaHig","outputId":"b10b2f52-d708-4568-cb5d-640b73573a62"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'transformer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-40d4ee917e0a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I don't think that you are expert.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'transformer' is not defined"]}],"source":["print(translate(transformer, \"I don't think that you are expert.\"))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2612,"status":"ok","timestamp":1744108762941,"user":{"displayName":"믕승","userId":"15077172607721463263"},"user_tz":-540},"id":"1KT8YeaD1cmt","outputId":"5a9cc4d2-7b87-4de2-abef-7b5d50c840fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n"]}],"source":["!pip install sacrebleu"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"OtVw-9Rtm3wi","executionInfo":{"status":"ok","timestamp":1744108762973,"user_tz":-540,"elapsed":28,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len - 1):\n","        tgt_mask = generate_square_subsequent_mask(ys.size(0)).to(DEVICE)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        next_word = torch.argmax(prob, dim=1).item()\n","        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BQW9dHqzqPPl","executionInfo":{"status":"ok","timestamp":1744108770239,"user_tz":-540,"elapsed":33,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[],"source":["def translate(model: nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1).to(DEVICE)\n","    src_mask = torch.zeros((src.size(0), src.size(0))).type(torch.bool).to(DEVICE)\n","\n","    tgt_tokens = greedy_decode(\n","        model, src, src_mask, max_len=50, start_symbol=BOS_IDX\n","    ).flatten()\n","\n","    # 🐞 .cpu().numpy() 대신 .cpu().tolist()를 사용하여 NumPy 의존성 제거\n","    return \" \".join(\n","        vocab_transform[TGT_LANGUAGE].lookup_tokens(tgt_tokens.cpu().tolist())\n","    ).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWZ342K5qVjz","outputId":"1df050cb-97e1-424b-fbf4-1f4f45d1f261","executionInfo":{"status":"ok","timestamp":1744110535375,"user_tz":-540,"elapsed":1438572,"user":{"displayName":"믕승","userId":"15077172607721463263"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"output_type":"stream","name":"stdout","text":["BLEU score: 34.57\n"]}],"source":["import sacrebleu\n","\n","# 모델 불러오기\n","model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                           NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM).to(DEVICE)\n","# model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_transformer_model_EN-KR.pth'))\n","# 🐞 map_location='cpu'를 추가하여 CPU에서 모델 로드\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/best_transformer_model_EN-KR.pth', map_location='cpu'))\n","\n","# 번역 예측 및 참조 데이터 준비\n","references = []\n","hypotheses = []\n","\n","# Using test data for evaluation\n","for src_sentence, tgt_sentence in zip(sents_en_in[-n_of_val:], sents_kr_out[-n_of_val:]):\n","    translated = translate(model, \" \".join(src_sentence)) # Join source sentence tokens\n","    hypotheses.append(translated.strip())\n","\n","    # 참조는 리스트 안에 리스트로 (BLEU의 다중 참조 구조 때문)\n","    references.append([\" \".join(tgt_sentence).strip()])  # Join target sentence tokens\n","\n","\n","# BLEU 점수 계산\n","bleu = sacrebleu.corpus_bleu(hypotheses, references)\n","print(f\"BLEU score: {bleu.score:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"i5LFq2nLaHig"},"source":["참고자료\n","========\n","\n","1.  Attention is all you need 논문.\n","    <https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf>\n","2.  Transformer에 대한 설명.\n","    <https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding>\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/PyTorchKorea/tutorials-kr/blob/master/docs/_downloads/c64c91cf87c13c0e83586b8e66e4d74e/translation_transformer.ipynb","timestamp":1743792273128}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}